{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.insert(0,'../python/')\n",
    "import correlation.correlation_utils as cu\n",
    "import popularity_model.popularity_model as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_id = '15o_pagerank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_stat_file = \"../correlation_experiments/%s_results.csv\" % dataset_id\n",
    "stat_df = pd.read_csv(dataset_stat_file, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract number of users in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print stat_df.columns[2]\n",
    "\n",
    "total_num_matcher = re.match(r'.*\\(total=(\\d+?)\\)', stat_df.columns[2], re.M|re.I)\n",
    "if not total_num_matcher:\n",
    "    raise RuntimeError(\"Column name does NOT match the regex!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(stat_df.columns)\n",
    "cols[2] = \"fraction_of_active_nodes\"\n",
    "stat_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_users = int(total_num_matcher.group(1))\n",
    "num_of_days = len(stat_df)#-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = list(stat_df[\"fraction_of_active_nodes\"])[:num_of_days]\n",
    "p_overlap = list(stat_df[\"fraction_of_users_in_2day_intersections\"])[:num_of_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations in real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_spearman = list(stat_df[\"spearman\"])[:num_of_days-1]\n",
    "data_w_spearman = list(stat_df[\"w_spearman\"])[:num_of_days-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print num_of_users, num_of_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pm.PopularityModel(num_of_users, num_of_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### I. popularity of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(model.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. daily variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(model.alpha[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. calculate daily centrality scores (without Markov model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(model.X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Introducing Markov model without leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_act = model.get_centrality_with_markov(p, p_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Introducing Markov model with leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_act_leaders = model.get_centrality_with_markov(p, p_overlap, lambda_=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export centrality scores (sorted daily toplists)\n",
    "\n",
    "   * Originally all active node were exported to files\n",
    "   * These nodes could have zero centrality values (e.g.: indegree, beta-measure)\n",
    "   * For PageRank there was no zero value as there is the probability of teleportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def export_daily_scores(output_folder, M):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for i in range(num_of_days):\n",
    "        f = open(output_folder + '/popularity_model_scores_%i.txt' % i,'w')\n",
    "        for j in range(num_of_users):\n",
    "            if M[i,j] > 0.0:\n",
    "                f.write('%i %f\\n' % (j,M[i,j]))\n",
    "        f.close()\n",
    "    print 'Daily scores were exported to files.'                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_prefix = \"/mnt/idms/fberes/NETWORK/andreas_article/nelly_model_scores/\"\n",
    "output_folder = output_prefix + '/%s/centrality_scores/' % dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "export_daily_scores(output_folder, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "export_daily_scores(output_folder, X_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_daily_scores(output_folder, X_act_leaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort by scores + (normalization was for learning to rank!!!)\n",
    "\n",
    "   * For normalization we divide the given value by the sum of scores\n",
    "   * This type of normalization was used for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subprocess.check_call(['../scripts/sort_all_output.sh', output_folder, \"True\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raise RuntimeWarning(\"You must wait for the sorting scripts to finish!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export centrality scores (learning to rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Popularity Model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_score_map(score_folder,day, measure):\n",
    "    \"\"\"The centrality maps were pre-sorted in decreasing order!!!\"\"\"\n",
    "    scores = pd.read_csv(score_folder + '/%s_scores_%i.txt_s' % (measure,day), sep=\" \", names=[\"id\",\"score_%i\" % day])\n",
    "    scores = scores.set_index(\"id\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_score_map(output_folder,0,measure=\"popularity_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_score_maps(score_folder, days, measure=\"popularity_model\"):\n",
    "    \"\"\"Load daily score maps. Then join them by ID.\"\"\"\n",
    "    daily_scores = load_score_map(score_folder,days[0],measure)\n",
    "    for i in range(1,len(days)):\n",
    "        print i, len(daily_scores)\n",
    "        current_scores = load_score_map(score_folder,days[i],measure)\n",
    "        daily_scores = daily_scores.join(current_scores, how='outer')\n",
    "    return daily_scores.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = load_score_maps(output_folder,range(num_of_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to set:\n",
    "\n",
    "   * Number of features (4-8) - this determines the available number of queries\n",
    "   * Index of queries (in test it will restart...)\n",
    "   * unseen true/false : the fatures cannot be all zero!!!\n",
    "   * top_k : the first k biggest label is included in the records\n",
    "   * Number of test queries: 1-3-5-7 (the remaining queries are the trains) - **Maybe I should send full query list - then Levente can split it into train and test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_learning_to_rank_input(score_df, num_of_features, k, unseen=True):\n",
    "    num_cols = score_df.columns\n",
    "    output_records = np.array([])\n",
    "    for i in range(num_of_features, len(num_cols)):\n",
    "        partial_score_mx = score_df.sort('score_%i' % i, ascending=0).head(k).as_matrix()\n",
    "        features_and_labels = partial_score_mx[:,i-num_of_features:i+1]\n",
    "        if not unseen: # filter records where all features are zero\n",
    "            filtered = []\n",
    "            for j in xrange(len(features_and_labels)):\n",
    "                if not np.array_equal(features_and_labels[j,:-1],[0]*num_of_features):\n",
    "                    filtered.append(list(features_and_labels[j,:]))\n",
    "            features_and_labels = np.array(filtered)\n",
    "        partial_output = np.zeros((len(features_and_labels),num_of_features+2))\n",
    "        partial_output[:,0] = i-num_of_features+1\n",
    "        partial_output[:,1:] = features_and_labels\n",
    "        if i == num_of_features:\n",
    "            output_records = partial_output\n",
    "        else:\n",
    "            output_records = np.concatenate((output_records,partial_output),axis=0)\n",
    "        #print partial_output.shape, output_records.shape\n",
    "    return output_records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2r_output_folder = '/mnt/idms/fberes/NETWORK/andreas_article/learning_to_rank_inputs/'\n",
    "#os.makedirs(l2r_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feat in [4,8]:\n",
    "    for k in [100,500]:\n",
    "        for unseen in [True,False]:\n",
    "            all_output = generate_learning_to_rank_input(scores, feat, k, unseen=unseen)\n",
    "            output_df = pd.DataFrame(all_output)\n",
    "            output_df[0] = output_df[0].astype('int')\n",
    "            output_df.to_csv(l2r_output_folder + \"%s_scores_k%i_f%i_unseen%s.csv\" % (dataset_id,k,feat,unseen), sep=\";\",index=False,header=False,float_format='%.10f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
