{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload centrality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_score_map(score_folder,day, measure):\n",
    "    \"\"\"The centrality maps were pre-sorted in decreasing order!!!\"\"\"\n",
    "    scores = pd.read_csv(score_folder + '/%s_scores_%i.txt_s' % (measure,day), sep=\" \", names=[\"id\",\"score_%i\" % day])\n",
    "    scores = scores.set_index(\"id\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_score_maps(score_folder, days, measure):\n",
    "    \"\"\"Load daily score maps. Then join them by ID.\"\"\"\n",
    "    daily_scores = load_score_map(score_folder,days[0],measure)\n",
    "    for i in range(1,len(days)):\n",
    "        print i, len(daily_scores)\n",
    "        current_scores = load_score_map(score_folder,days[i],measure)\n",
    "        daily_scores = daily_scores.join(current_scores, how='outer')\n",
    "    return daily_scores.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_id = \"olympics\"\n",
    "\n",
    "#measure_prefix = \"in_degree\"\n",
    "measure_prefix = \"pagerank\"\n",
    "input_folder = \"/mnt/idms/fberes/NETWORK/DATA/temporal_centralities/centrality_output_for_datasets_normalized/%s/centrality_scores/\" % dataset_id\n",
    "\n",
    "#measure_prefix = \"popularity_model\"\n",
    "#input_folder = \"/mnt/idms/fberes/NETWORK/andreas_article/nelly_model_scores/%s/centrality_scores/\" % dataset_id\n",
    "\n",
    "days = range(21)\n",
    "\n",
    "print measure_prefix\n",
    "print days\n",
    "print input_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = load_score_maps(input_folder,days,measure=measure_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export centrality scores (learning to rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to set:\n",
    "\n",
    "   * Number of features (4-8) - this determines the available number of queries\n",
    "   * unseen true/false : the fatures cannot be all zeros = unseenTrue\n",
    "   * top_k : the first k biggest label is included in the records\n",
    "   * the output have to be splitted for train and test (later by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_learning_to_rank_input(score_df, num_of_features, k, unseen=True):\n",
    "    num_cols = score_df.columns\n",
    "    output_records = np.array([])\n",
    "    for i in range(num_of_features, len(num_cols)):\n",
    "        partial_score_mx = score_df.sort('score_%i' % i, ascending=0).head(k).as_matrix()\n",
    "        features_and_labels = partial_score_mx[:,i-num_of_features:i+1]\n",
    "        if not unseen: # filter records where all features are zero\n",
    "            filtered = []\n",
    "            for j in xrange(len(features_and_labels)):\n",
    "                if not np.array_equal(features_and_labels[j,:-1],[0]*num_of_features):\n",
    "                    filtered.append(list(features_and_labels[j,:]))\n",
    "            features_and_labels = np.array(filtered)\n",
    "        partial_output = np.zeros((len(features_and_labels),num_of_features+2))\n",
    "        partial_output[:,0] = i-num_of_features+1\n",
    "        partial_output[:,1:] = features_and_labels\n",
    "        if i == num_of_features:\n",
    "            output_records = partial_output\n",
    "        else:\n",
    "            output_records = np.concatenate((output_records,partial_output),axis=0)\n",
    "        #print partial_output.shape, output_records.shape\n",
    "    return output_records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if measure_prefix == \"popularity_model\":\n",
    "    l2r_output_folder = '/mnt/idms/fberes/NETWORK/andreas_article/learning_to_rank_inputs/popularity_model/'\n",
    "else:\n",
    "    l2r_output_folder = '/mnt/idms/fberes/NETWORK/andreas_article/learning_to_rank_inputs/original_datasets/'\n",
    "#os.makedirs(l2r_output_folder)\n",
    "print l2r_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feat in [4]:\n",
    "    for k in [100,500]:\n",
    "        for unseen in [True,False]:\n",
    "            all_output = generate_learning_to_rank_input(scores, feat, k, unseen=unseen)\n",
    "            output_df = pd.DataFrame(all_output)\n",
    "            output_df[0] = output_df[0].astype('int')\n",
    "            #print len(output_df)\n",
    "            output_df.to_csv(l2r_output_folder + \"%s_%s_k%i_f%i_unseen%s.csv\" % (dataset_id,measure_prefix,k,feat,unseen), sep=\";\",index=False,header=False,float_format='%.10f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
