{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0,'../python/')\n",
    "import correlation.correlation_utils as cu\n",
    "import popularity_model.popularity_model as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_id = 'oc_pagerank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_stat_file = \"../correlation_experiments/%s_results.csv\" % dataset_id\n",
    "stat_df = pd.read_csv(dataset_stat_file, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract number of users in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print stat_df.columns[2]\n",
    "\n",
    "total_num_matcher = re.match(r'.*\\(total=(\\d+?)\\)', stat_df.columns[2], re.M|re.I)\n",
    "if not total_num_matcher:\n",
    "    raise RuntimeError(\"Column name does NOT match the regex!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(stat_df.columns)\n",
    "cols[2] = \"fraction_of_active_nodes\"\n",
    "stat_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kendall's Tau is computation intensive: so only a small sample is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_users = 5000 #int(total_num_matcher.group(1))\n",
    "num_of_days = len(stat_df)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = list(stat_df[\"fraction_of_active_nodes\"])[:num_of_days]\n",
    "p_overlap = list(stat_df[\"fraction_of_users_in_2day_intersections\"])[:num_of_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations in real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_kendall = list(stat_df[\"kendall\"])[:num_of_days-1]\n",
    "data_w_kendall = list(stat_df[\"w_kendall\"])[:num_of_days-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print num_of_users, num_of_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: fit powerlaw exponent on real data aggregated centrality values!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pm.PopularityModel(num_of_users, num_of_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### I. popularity of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(model.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. daily variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(model.alpha[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. calculate daily centrality scores (without Markov model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(model.X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Introducing Markov model without leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_act = model.get_centrality_with_markov(p, p_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Introducing Markov model with leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_act_leaders = model.get_centrality_with_markov(p, p_overlap, lambda_=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "\n",
    "def tiedrank(vector):\n",
    "    return (len(vector) + 1) * np.ones(len(vector)) - ss.rankdata(vector)\n",
    "\n",
    "def get_list_for_corr(M,day_idx):\n",
    "    idx = day_idx\n",
    "    day_one = np.ceil(M[idx,:])\n",
    "    day_two = np.ceil(M[idx+1,:])\n",
    "\n",
    "    ind_one=np.nonzero(day_one)[0];\n",
    "    ind_two=np.nonzero(day_two)[0];\n",
    "    ind=np.union1d(ind_one,ind_two)\n",
    "\n",
    "    ranks_day_one=tiedrank(day_one[ind])\n",
    "    ranks_day_two=tiedrank(day_two[ind])\n",
    "    return ranks_day_one, ranks_day_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_list_0, rank_list_1 = get_list_for_corr(X_act_leaders,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findWKendall(rankX,rankY):\n",
    "    n = len(rankX)\n",
    "    denomX=0\n",
    "    denomY=0\n",
    "    denomXW=0\n",
    "    denomYW=0\n",
    "    num=0\n",
    "    numW=0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            weightXY= 1/rankY[i]+1/rankY[j]\n",
    "            weightX=1/rankX[i]+1/rankX[j];\n",
    "            weightY=1/rankY[i]+1/rankY[j];\n",
    "            termX=np.sign(rankX[i]-rankX[j]);\n",
    "            termY=np.sign(rankY[i]-rankY[j]);\n",
    "            denomX=denomX+(termX)**2;\n",
    "            denomY=denomY+(termY)**2;\n",
    "            denomXW=denomXW+(termX)**2*weightX;\n",
    "            denomYW=denomYW+(termY)**2*weightY;\n",
    "            num=num+termX*termY;\n",
    "            numW=numW+termX*termY*weightXY;\n",
    "\n",
    "    Kendall=num/math.sqrt(denomX*denomY);\n",
    "    WKendall=numW/math.sqrt(denomXW*denomYW);\n",
    "    return [Kendall, WKendall]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import multiprocessing\n",
    "import itertools\n",
    "\n",
    "def worker_init(rank_a,rank_b):\n",
    "    global rankX\n",
    "    global rankY\n",
    "    rankX = rank_a\n",
    "    rankY = rank_b\n",
    "\n",
    "def worker(tuple_):\n",
    "    i, j = tuple_[0], tuple_[1]\n",
    "    weightXY= 1/rankY[i]+1/rankY[j]\n",
    "    weightX=1/rankX[i]+1/rankX[j]\n",
    "    weightY=1/rankY[i]+1/rankY[j]\n",
    "    termX=np.sign(rankX[i]-rankX[j])\n",
    "    termY=np.sign(rankY[i]-rankY[j])\n",
    "    # denomX, denomY, denomXW, denomYW, num, numW\n",
    "    return i, j, [termX**2, termY**2, termX**2*weightX, termY**2*weightY, termX*termY, termX*termY*weightXY]\n",
    "\n",
    "def findWKendall2(rank_a,rank_b,num_proc=None):\n",
    "    \"\"\"parallel implementation\"\"\"\n",
    "    size = len(rank_a)\n",
    "    denomX = np.zeros((size,size))\n",
    "    denomY = np.zeros((size,size))\n",
    "    denomXW = np.zeros((size,size))\n",
    "    denomYW = np.zeros((size,size))\n",
    "    num = np.zeros((size,size))\n",
    "    numW = np.zeros((size,size))\n",
    "    \n",
    "    pool = multiprocessing.Pool(processes=num_proc,initializer=worker_init, initargs=(rank_a,rank_b,))\n",
    "    for i, j, val in pool.map(worker, itertools.combinations(range(size), 2)):\n",
    "        denomX[i,j] = val[0] \n",
    "        denomY[i,j] = val[1] \n",
    "        denomXW[i,j] = val[2] \n",
    "        denomYW[i,j] = val[3] \n",
    "        num[i,j] = val[4] \n",
    "        numW[i,j] = val[5]\n",
    "    Kendall=num.sum()/math.sqrt(denomX.sum()*denomY.sum());\n",
    "    WKendall=numW.sum()/math.sqrt(denomXW.sum()*denomYW.sum());\n",
    "    pool.close()\n",
    "    return Kendall, WKendall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print stats.kendalltau(rank_list_0, rank_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "findWKendall(rank_list_0, rank_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "findWKendall2(rank_list_0, rank_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export centrality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def export_daily_scores(output_folder, M):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for i in range(num_of_days):\n",
    "        f = open(output_folder + '/centrality_scores_%i.txt' % i,'w')\n",
    "        for j in range(num_of_users):\n",
    "            if M[i,j] > 0.0:\n",
    "                f.write('%i %f\\n' % (j,M[i,j]))\n",
    "        f.close()\n",
    "    print 'Daily scores were exported to files.'                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export_daily_scores('../correlation_experiments/kendall_%s_nelly_model/centrality_scores/' % dataset_id, X_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export_daily_scores('../correlation_experiments/%s_nelly_model/centrality_scores/' % dataset_id, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export_daily_scores('../correlation_experiments/%s_nelly_model_markov/centrality_scores/' % dataset_id, X_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export_daily_scores('../correlation_experiments/%s_nelly_model_leaders/centrality_scores/' % dataset_id, X_act_leaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_correlations(num_of_days, values, labels, caption, figsize=(10,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(caption)\n",
    "    for i in range(len(values)):\n",
    "        plt.plot(range(num_of_days-1),values[i],'-o',label=labels[i])\n",
    "    plt.ylim(-1.0,1.1)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "reload(cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import operator\n",
    "\n",
    "def get_correlations(A, num_of_days):\n",
    "    kendall = []\n",
    "    for i in xrange(1,num_of_days):\n",
    "        rank_list_0, rank_list_1 = get_list_for_corr(A,i-1)\n",
    "        kendall.append(stats.kendalltau(rank_list_0,rank_list_1)[0])\n",
    "    return kendall\n",
    "    \n",
    "def filter_active_users(A, num_of_days):\n",
    "    num_users = A.shape[1]\n",
    "    centrality_maps = []\n",
    "    for i in range(num_of_days):\n",
    "        centrality_maps.append({})\n",
    "        for j in range(num_users):\n",
    "            val = A[i,j]\n",
    "            if val > 0.0:\n",
    "                centrality_maps[i][j] = val\n",
    "    return centrality_maps\n",
    "\n",
    "def get_custom_correlations(A, num_of_days):\n",
    "    \"\"\"Return unweighted and weighted correlations\"\"\"\n",
    "    res = []\n",
    "    for i in xrange(1,num_of_days):\n",
    "        rank_list_0, rank_list_1 = get_list_for_corr(A,i-1)\n",
    "        res.append(findWKendall(rank_list_0,rank_list_1))\n",
    "    return np.array(res)\n",
    "    #return cu.compute_correlation_sequential(filter_active_users(A,num_of_days),corr_type=\"kendall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) correlations without Markov model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scipy correlation code\n",
    "\n",
    "   * there is no fit to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kendall = get_correlations(model.X, num_of_days)\n",
    "plot_correlations(num_of_days,[kendall,data_kendall],['model','data'],\"Kendall's Tau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom correlation code\n",
    "\n",
    "   * there is no fit to real data (YET)\n",
    "   * we have the same results as the scipy implementation for unweighted spearman (this is good!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "res = get_custom_correlations(model.X, num_of_days)\n",
    "kendall, w_kendall = list(res[:,0]), list(res[:,1])\n",
    "label_list = ['model_kendall','data_kendall','model_w_kendall','data_w_kendall']\n",
    "plot_correlations(num_of_days,[kendall,data_kendall,w_kendall,data_w_kendall],label_list,\"Kendall's Tau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) correlations with Markov model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scipy correlation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kendall = get_correlations(X_act, num_of_days)\n",
    "plot_correlations(num_of_days,[kendall,data_kendall],['model','data'],\"Kendall's Tau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom correlation code\n",
    "\n",
    "   * there is NO match between the model and the data for normal Kendall's Tau\n",
    "   * the weighted Kendall's correlation is close to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = get_custom_correlations(X_act, num_of_days)\n",
    "kendall, w_kendall = list(res[:,0]), list(res[:,1])\n",
    "label_list = ['model_kendall','data_kendall','model_w_kendall','data_w_kendall']\n",
    "plot_correlations(num_of_days,[kendall,data_kendall,w_kendall,data_w_kendall],label_list,\"Kendall's Tau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) correlations with Markov model and Leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_act_leaders = model.get_centrality_with_markov(p, p_overlap, lambda_=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scipy correlation code\n",
    "\n",
    "   * there is no effect of the leaders\n",
    "   * there is still _positive correlations_ (because of too many 0.0 centralities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kendall = get_correlations(X_act_leaders, num_of_days)\n",
    "plot_correlations(num_of_days,[kendall,data_kendall],['model','data'],\"Kendall's Tau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom correlation code\n",
    "\n",
    "   * even better results than without leaders\n",
    "   * unweighted spearman is almost a perfect match on model and real data\n",
    "   * weighted spearman fits much better to real data with the introduction of leaders (as expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = get_custom_correlations(X_act_leaders, num_of_days)\n",
    "kendall, w_kendall = list(res[:,0]), list(res[:,1])\n",
    "label_list = ['model_kendall','data_kendall','model_w_kendall','data_w_kendall']\n",
    "plot_correlations(num_of_days,[kendall,data_kendall,w_kendall,data_w_kendall],label_list,\"Kendall's Tau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
