{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.insert(0,'../../python/')\n",
    "import correlation.correlation_utils as cu\n",
    "import popularity_model.popularity_model as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notenook only support popularity model score generation for pagerank. The optimal lambda parameters and daily correlations for indegree must be computed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_map = {'maidan':0.1,'15o':0.3,'oc':0.3,'olympics':0.1,'yo':0.2}\n",
    "print lambda_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_id = 'yo'\n",
    "measure_id = \"pagerank\"\n",
    "\n",
    "input_prefix = \"/mnt/idms/fberes/NETWORK/andreas_article/results/corr_and_stats/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LAMBDA = 0.0\n",
    "for key in lambda_map:\n",
    "    if key == dataset_id:\n",
    "        print key, lambda_map[key]\n",
    "        LAMBDA=lambda_map[key]\n",
    "        break\n",
    "if LAMBDA == 0.0:\n",
    "    raise RuntimeError(\"Lambda were not found!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_stat_file = input_prefix + \"/%s_%s.csv\" % (dataset_id, measure_id)\n",
    "stat_df = pd.read_csv(dataset_stat_file, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_days = len(stat_df)\n",
    "num_of_users = 0\n",
    "with open(input_prefix + \"/%s_total_vertex_count.txt\" % (dataset_id)) as f:\n",
    "    num_of_users = int(f.readline())\n",
    "if num_of_users == 0:\n",
    "    raise RuntimeError('Invalid total vertex count!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print num_of_users, num_of_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = list(stat_df[\"prev_day_frac\"])[:num_of_days]\n",
    "p_overlap = list(stat_df[\"overlap_frac\"])[:num_of_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations in real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pearson = list(stat_df[\"pearson\"])[:num_of_days-1]\n",
    "data_spearman = list(stat_df[\"spearman\"])[:num_of_days-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pm.PopularityModel(num_of_users, num_of_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### I. popularity of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ax = sns.distplot(model.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. daily variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "ax = sns.distplot(model.alpha[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. calculate daily centrality scores (without Markov model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ax = sns.distplot(model.X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Introducing Markov model without leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_act = model.get_centrality_with_markov(p, p_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Introducing Markov model with leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_act_leaders = model.get_centrality_with_markov(p, p_overlap, lambda_=LAMBDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export centrality scores (sorted daily toplists)\n",
    "\n",
    "   * Originally all active node were exported to files\n",
    "   * These nodes could have zero centrality values (e.g.: indegree, beta-measure)\n",
    "   * For PageRank there was no zero value as there is the probability of teleportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def export_daily_scores(output_folder, M, measure_type):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for i in range(num_of_days):\n",
    "        f = open(output_folder + '/%s_scores_%i.txt' % (measure_type,i),'w')\n",
    "        for j in range(num_of_users):\n",
    "            if M[i,j] > 0.0:\n",
    "                f.write('%i %f\\n' % (j,M[i,j]))\n",
    "        f.close()\n",
    "    print 'Daily scores were exported to files.'                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_prefix = \"/mnt/idms/fberes/NETWORK/andreas_article/popularity_model/%s\" % dataset_id\n",
    "output_folder = output_prefix + '/centrality_scores/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_daily_scores(output_folder, X_act_leaders, measure_type=measure_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write the selected LAMBDA value to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(output_prefix + '/%s_lambda.txt' % measure_id, 'w') as f:\n",
    "    f.write(str(LAMBDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort by scores + (normalization was applied for learning to rank input!!!)\n",
    "\n",
    "   * For normalization we divide the given value by the sum of scores\n",
    "   * This type of normalization was used for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subprocess.check_call(['../../scripts/sort_all_output.sh', output_folder, \"True\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
