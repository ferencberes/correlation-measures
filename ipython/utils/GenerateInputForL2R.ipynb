{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../pipelines/LearningToRankInput.json\",sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload centrality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_score_map(score_folder,day, measure):\n",
    "    \"\"\"The centrality maps were pre-sorted in decreasing order!!!\"\"\"\n",
    "    scores = pd.read_csv(score_folder + '/%s_scores_%i.txt_s' % (measure,day), sep=\" \", names=[\"id\",\"score_%i\" % day])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_score_maps(score_folder, days, measure):\n",
    "    \"\"\"Load daily score maps. Then join them by ID.\"\"\"\n",
    "    daily_scores = load_score_map(score_folder,days[0],measure)\n",
    "    for i in range(1,len(days)):\n",
    "        print i, len(daily_scores)\n",
    "        current_scores = load_score_map(score_folder,days[i],measure)\n",
    "        daily_scores = pd.merge(daily_scores,current_scores,on=\"id\",how='outer')\n",
    "    daily_scores = daily_scores.fillna(0.0)\n",
    "    daily_scores = daily_scores.set_index(\"id\")\n",
    "    return daily_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_folder = ph.get(\"experiment_folder\")\n",
    "dataset_id = ph.get(\"dataset_id\")\n",
    "measure_prefix = ph.get(\"measure_id\")\n",
    "is_popularity_model = ph.get(\"is_popularity_model\")\n",
    "if is_popularity_model:\n",
    "    input_folder = \"%s/popularity_model/%s/centrality_scores/\" % (experiment_folder, dataset_id)\n",
    "else:\n",
    "    input_folder = \"/mnt/idms/fberes/network/DATA/temporal_centralities/centrality_output_for_datasets_normalized/%s/centrality_scores/\" % dataset_id\n",
    "days = range(21)\n",
    "\n",
    "print is_popularity_model\n",
    "print dataset_id, measure_prefix\n",
    "print input_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = load_score_maps(input_folder,days,measure=measure_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export centrality scores (learning to rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to set:\n",
    "\n",
    "   * Number of features (4-8) - this determines the available number of queries\n",
    "   * unseen true/false : the fatures cannot be all zeros = unseenTrue\n",
    "   * top_k : the first k biggest label is included in the records\n",
    "   * the output have to be splitted for train and test (later by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_learning_to_rank_input(score_df, num_of_features, k, unseen=True, append_ids=False):\n",
    "    \"\"\"If unseen==False then all formerly not seen records are removed.\"\"\"\n",
    "    cols = score_df.columns\n",
    "    output_records = np.array([])\n",
    "    for i in range(num_of_features, len(cols)):\n",
    "        partial_df = score_df.sort('score_%i' % i, ascending=0).head(k)\n",
    "        #print partial_df.head()\n",
    "        partial_score_mx = partial_df.as_matrix()\n",
    "        # last column is the label, other columns are the features (if append_ids==False)\n",
    "        features_and_labels = partial_score_mx[:,i-num_of_features:i+1]\n",
    "        if not unseen:\n",
    "            filtered = []\n",
    "            node_ids = []\n",
    "            for j in xrange(len(features_and_labels)):\n",
    "                # filter records where all features are zero\n",
    "                if not np.array_equal(features_and_labels[j,:-1],[0]*num_of_features):\n",
    "                    filtered.append(list(features_and_labels[j,:]))\n",
    "                    node_ids.append(partial_df.index[j])\n",
    "            features_and_labels = np.array(filtered)\n",
    "        else:\n",
    "            node_ids = partial_df.index\n",
    "        if append_ids:\n",
    "            tmp_arr = np.zeros((features_and_labels.shape[0], features_and_labels.shape[1]+1))\n",
    "            tmp_arr[:,:-1] = features_and_labels\n",
    "            tmp_arr[:,-1] = node_ids\n",
    "            features_and_labels = tmp_arr\n",
    "            partial_output = np.zeros((len(features_and_labels),num_of_features+3))\n",
    "        else:\n",
    "            partial_output = np.zeros((len(features_and_labels),num_of_features+2))\n",
    "        partial_output[:,0] = i-num_of_features+1\n",
    "        partial_output[:,1:] = features_and_labels\n",
    "        if i == num_of_features:\n",
    "            output_records = partial_output\n",
    "        else:\n",
    "            output_records = np.concatenate((output_records,partial_output),axis=0)\n",
    "        #print partial_output.shape, output_records.shape\n",
    "    return output_records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if is_popularity_model:\n",
    "    l2r_output_folder = '%s/learning_to_rank_inputs/popularity_model/' % experiment_folder\n",
    "else:\n",
    "    l2r_output_folder = '%s/learning_to_rank_inputs/original_datasets/' % experiment_folder\n",
    "if not os.path.exists(l2r_output_folder):\n",
    "    os.makedirs(l2r_output_folder)\n",
    "print l2r_output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 10 digits for floating point numbers in the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feat in [4]:\n",
    "    for k in [100,500]:\n",
    "        for unseen in [True,False]:\n",
    "            all_output = generate_learning_to_rank_input(scores, feat, k, unseen=unseen)\n",
    "            output_df = pd.DataFrame(all_output)\n",
    "            output_df[0] = output_df[0].astype('int')\n",
    "            #print len(output_df)\n",
    "            output_df.to_csv(l2r_output_folder + \"%s_%s_k%i_f%i_unseen%s.csv\" % (dataset_id,measure_prefix,k,feat,unseen), sep=\";\",index=False,header=False,float_format='%.10f')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-env]",
   "language": "python",
   "name": "conda-env-dm-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}